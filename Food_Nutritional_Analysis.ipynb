{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Food Product and Nutrition Analysis System\n",
        "\n",
        "Author: Jacob Yi\n",
        "\n",
        "## Primary Goals\n",
        "\n",
        "### 1. Nutritional Quality Assessment\n",
        "- **Standardized Scoring System:** Develop a standardized scoring system for evaluating the nutritional quality of food products.\n",
        "- **Informed Choices:** Empower consumers to make informed dietary choices through transparent and accessible nutritional information.\n",
        "- **Product Comparisons:** Facilitate easy comparison of food products within the same category based on their nutritional content.\n",
        "\n",
        "### 2. Product Classification & Grouping\n",
        "- **Categorization:** Automatically categorize products based on their ingredients and nutritional content.\n",
        "- **Cross-Brand Comparison:** Identify and compare similar products across different brands.\n",
        "- **Health Impact Grouping:** Group products according to their potential health impacts, aiding in healthier product selection.\n",
        "\n",
        "### 3. Pattern Discovery\n",
        "- **Ingredient-Nutrition Relationships:** Explore and identify relationships between specific ingredients and nutritional outcomes.\n",
        "- **Trend Analysis:** Analyze trends in product formulation to uncover evolving patterns in the food industry.\n",
        "- **Product Improvement Opportunities:** Discover opportunities for product improvement and innovation, driving forward the industry's commitment to health.\n"
      ],
      "metadata": {
        "id": "-EZSA52l14Wq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import and Install required libraries.**"
      ],
      "metadata": {
        "id": "PxVimjcO3mEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install additional required packages\n",
        "!pip install plotly\n",
        "!pip install wordcloud\n",
        "!pip install pandasql\n",
        "\n",
        "# Standard data processing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandasql import sqldf\n",
        "import json\n",
        "import datetime as dt\n",
        "import re\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import cm\n",
        "import plotly.express as px\n",
        "\n",
        "# Machine Learning & PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "juLwaJem3sQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!apt update\n",
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "zOxrGmdq6Dm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Data Loading and Initial Exploration"
      ],
      "metadata": {
        "id": "pUo0fgf04CXu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Loading the Dataset**\n",
        "Download dataset from kaggle"
      ],
      "metadata": {
        "id": "BxzKy0LUF7_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version of the dataset\n",
        "path = kagglehub.dataset_download(\"openfoodfacts/world-food-facts\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "LwZxvzHt65A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obtain TSV file"
      ],
      "metadata": {
        "id": "qY0U176WJ__h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to TSV file\n",
        "file_path = path + '/en.openfoodfacts.org.products.tsv'\n",
        "\n",
        "# Load the dataset\n",
        "df_food = pd.read_csv(file_path, sep='\\t', encoding='utf-8', low_memory=False)\n",
        "\n",
        "# Display initial information\n",
        "print(\"\\nDataset Info:\")\n",
        "print(\"-\" * 50)\n",
        "print(df_food.info())"
      ],
      "metadata": {
        "id": "fpYZ0s0X9fVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_food.head()"
      ],
      "metadata": {
        "id": "x8rgWDE8Vg_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape\n",
        "print(\"Shape of the dataset:\", df_food.shape)"
      ],
      "metadata": {
        "id": "5jZUF6NaU6d_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Columns\n",
        "print(\"Columns in the dataset:\")\n",
        "print(df_food.columns)\n",
        "print(\"Number of columns:\", len(df_food.columns))"
      ],
      "metadata": {
        "id": "TIUVzo6yVAuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Rows\n",
        "print(\"Rows in the dataset:\")\n",
        "print(df_food.index)\n",
        "print(\"Number of rows:\", len(df_food))"
      ],
      "metadata": {
        "id": "DYCnI11_VNnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Peak at first five rows.\n",
        "display(df_food.head())"
      ],
      "metadata": {
        "id": "613nPzDwCRog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing values\n",
        "missing = df_food.isnull().sum()\n",
        "print(\"\\nMissing Values:\")\n",
        "print(\"-\" * 50)\n",
        "print(missing[missing > 0])"
      ],
      "metadata": {
        "id": "aPo4YEJAVa9x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Data Quality Assessment**"
      ],
      "metadata": {
        "id": "mBac2raSGIiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quality_metrics = {}\n",
        "\n",
        "# Basic statistics\n",
        "quality_metrics['total_rows'] = len(df_food)\n",
        "quality_metrics['total_columns'] = len(df_food.columns)\n",
        "\n",
        "# Missing values\n",
        "missing_vals = df_food.isnull().sum()\n",
        "quality_metrics['columns_with_nulls'] = missing_vals[missing_vals > 0]\n",
        "\n",
        "# Duplicate check\n",
        "quality_metrics['duplicate_rows'] = df_food.duplicated().sum()\n",
        "\n",
        "# Nutrition columns check\n",
        "nutrition_cols = [col for col in df_food.columns if '_100g' in col]\n",
        "quality_metrics['nutrition_columns'] = nutrition_cols\n",
        "\n",
        "# Invalid values in nutrition columns\n",
        "invalid_counts = {}\n",
        "for col in nutrition_cols:\n",
        "    # Combine conditions to avoid misalignment\n",
        "    invalid = df_food[\n",
        "        df_food[col].notna() &\n",
        "        ((df_food[col] < 0) | (df_food[col] > 100))\n",
        "    ].shape[0]\n",
        "    if invalid > 0:\n",
        "        invalid_counts[col] = invalid\n",
        "\n",
        "quality_metrics['invalid_values'] = invalid_counts"
      ],
      "metadata": {
        "id": "p8mJk3I-Hrl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display results\n",
        "print(\"Data Quality Assessment Results:\")\n",
        "print(\"-\" * 50)\n",
        "for metric, value in quality_metrics.items():\n",
        "    print(f\"\\n{metric}:\")\n",
        "    print(value)"
      ],
      "metadata": {
        "id": "5Pyf-AIrIULn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.3 Data Cleaning**"
      ],
      "metadata": {
        "id": "vae_YzzkGi1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting data cleaning...\")\n",
        "print(f\"Initial shape: {df_food.shape}\")"
      ],
      "metadata": {
        "id": "hQxkrDpyj-S5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a copy\n",
        "df_clean = df_food.copy()\n",
        "\n",
        "# Select essential columns - focusing on key nutritional info\n",
        "essential_cols = [\n",
        "    'code', 'product_name', 'brands', 'categories',\n",
        "    'energy_100g', 'proteins_100g', 'carbohydrates_100g',\n",
        "    'fat_100g', 'fiber_100g', 'sugars_100g', 'salt_100g',\n",
        "    'nutrition-score-fr_100g'\n",
        "]\n",
        "\n",
        "df_clean = df_clean[essential_cols]\n",
        "print(f\"After selecting essential columns: {df_clean.shape}\")\n",
        "\n",
        "# Remove duplicates based on code\n",
        "df_clean = df_clean.drop_duplicates(subset=['code'])\n",
        "\n",
        "# Clean text columns using .loc to avoid warnings\n",
        "text_cols = ['product_name', 'brands', 'categories']\n",
        "for col in text_cols:\n",
        "    df_clean.loc[:, col] = df_clean[col].fillna('').astype(str).str.strip().str.lower()\n",
        "\n",
        "# Handle missing values in nutrition columns\n",
        "nutrition_cols = ['energy_100g', 'proteins_100g', 'carbohydrates_100g',\n",
        "                  'fat_100g', 'fiber_100g', 'salt_100g']\n",
        "\n",
        "for col in nutrition_cols:\n",
        "    # Replace invalid values (negative or extreme outliers)\n",
        "    mask = (df_clean[col] < 0) | (df_clean[col] > df_clean[col].quantile(0.99))\n",
        "    df_clean.loc[mask, col] = np.nan\n",
        "\n",
        "    # Fill remaining NaN with median\n",
        "    median_val = df_clean[col].median()\n",
        "    df_clean[col] = df_clean[col].fillna(median_val)\n",
        "\n",
        "\n",
        "print(f\"After removing duplicates: {df_clean.shape}\")\n",
        "\n",
        "print(\"Cleaning Results:\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"Original shape: {df_food.shape}\")\n",
        "print(f\"Cleaned shape: {df_clean.shape}\")"
      ],
      "metadata": {
        "id": "HVa6_A2hIl-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.head()"
      ],
      "metadata": {
        "id": "ilfZPtwpjAfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.4 Feature Engineering**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4V-xe7GFV0lY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#### 1. Calculate caloric content based on macronutrients\n",
        "\n",
        "Following standard conversion:\n",
        "- Proteins: 4 kcal/g\n",
        "- Carbohydrates: 4 kcal/g\n",
        "- Fats: 9 kcal/g"
      ],
      "metadata": {
        "id": "P88V54vVd99m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_engineered = df_clean.copy()\n",
        "\n",
        "# Calculate calories from macronutrients\n",
        "df_engineered['calories_from_proteins'] = df_engineered['proteins_100g'] * 4\n",
        "df_engineered['calories_from_carbs'] = df_engineered['carbohydrates_100g'] * 4\n",
        "df_engineered['calories_from_fat'] = df_engineered['fat_100g'] * 9\n",
        "\n",
        "# Calculate total calories from macronutrients\n",
        "df_engineered['calculated_calories'] = (df_engineered['calories_from_proteins'] +\n",
        "                            df_engineered['calories_from_carbs'] +\n",
        "                            df_engineered['calories_from_fat'])\n",
        "\n",
        "# Compare with reported energy\n",
        "df_engineered['calorie_difference'] = df_engineered['energy_100g'] - df_engineered['calculated_calories']"
      ],
      "metadata": {
        "id": "YwbNKKvcVz11"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Calculate macronutrient ratio from total macros"
      ],
      "metadata": {
        "id": "kkmvEq_Fdz_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate macronutrient ratios\n",
        "total_macros = (df_engineered['proteins_100g'] + df_engineered['carbohydrates_100g'] + df_engineered['fat_100g'])\n",
        "df_engineered['protein_ratio'] = df_engineered['proteins_100g'] / total_macros\n",
        "df_engineered['carb_ratio'] = df_engineered['carbohydrates_100g'] / total_macros\n",
        "df_engineered['fat_ratio'] = df_engineered['fat_100g'] / total_macros"
      ],
      "metadata": {
        "id": "aoTHh5O7aAp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Calculate Nutrient Density Score based on modified NRF Index\n",
        "    \n",
        "Beneficial nutrients (encouraged):\n",
        "- Protein: Essential for body function\n",
        "- Fiber: Digestive health\n",
        "- Vitamins/Minerals (if available)\n",
        "\n",
        "Nutrients to limit:\n",
        "- Sodium (salt)\n",
        "- Saturated fat\n",
        "- Added sugars\n",
        "\n",
        "Score = (% DV of beneficial nutrients - % DV of nutrients to limit) / calories per 100g\n",
        "\n",
        "Source:\n",
        "https://www.sciencedirect.com/science/article/pii/S0002916523017847"
      ],
      "metadata": {
        "id": "elUTDmvcd3_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Daily Value references (based on 2000 calorie diet)\n",
        "DV = {\n",
        "    'proteins': 50,  # g\n",
        "    'fiber': 25,    # g\n",
        "    'salt': 2.3,    # g\n",
        "    'saturated_fat': 20  # g\n",
        "}\n",
        "\n",
        "# Calculate percentage of daily value for each nutrient\n",
        "beneficial_nutrients = (\n",
        "    (df_engineered['proteins_100g'] / DV['proteins'] * 100) +  # Protein DV%\n",
        "    (df_engineered['fiber_100g'] / DV['fiber'] * 100)         # Fiber DV%\n",
        ")\n",
        "\n",
        "nutrients_to_limit = (\n",
        "    (df_engineered['salt_100g'] / DV['salt'] * 100)   # Salt DV%\n",
        ")\n",
        "\n",
        "# Calculate nutrition density score\n",
        "# Cap percentages at 100% to avoid skewing from fortified foods\n",
        "df_engineered['nutrition_density_score'] = (\n",
        "    np.minimum(beneficial_nutrients, 100) -\n",
        "    np.minimum(nutrients_to_limit, 100)\n",
        ") / (df_engineered['energy_100g'] / 100)  # Per 100 calories\n",
        "\n",
        "# Add interpretable categories\n",
        "df_engineered['nutrition_density_category'] = pd.cut(\n",
        "    df_engineered['nutrition_density_score'],\n",
        "    bins=[-float('inf'), -1, 0, 1, float('inf')],\n",
        "    labels=['Poor', 'Fair', 'Good', 'Excellent']\n",
        ")\n",
        "\n",
        "# Clip extreme values and handle division by zero\n",
        "df_engineered['nutrition_density_score'] = df_engineered['nutrition_density_score'].replace([np.inf, -np.inf], np.nan)\n",
        "# Fill NaN from infinity with a capped value or 0\n",
        "df_engineered['nutrition_density_score'] = df_engineered['nutrition_density_score'].fillna(0)"
      ],
      "metadata": {
        "id": "4hRSaJlFaBBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Categorize Products\n",
        "\n",
        "Sort by high values of protein, fiber, and salt."
      ],
      "metadata": {
        "id": "Sr2qbJ06d6_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize products\n",
        "df_engineered['is_high_protein'] = (df_engineered['protein_ratio'] > 0.3).astype(int)\n",
        "df_engineered['is_high_fiber'] = (df_engineered['fiber_100g'] > 6).astype(int)\n",
        "df_engineered['is_high_salt'] = (df_engineered['salt_100g'] > 1.5).astype(int)\n",
        "\n",
        "print(\"\\nFeature Engineering Results:\")\n",
        "print(\"-\" * 50)\n",
        "print(\"\\nNutritional Features:\")\n",
        "print(df_engineered[['calories_from_proteins', 'calories_from_carbs',\n",
        "                     'calories_from_fat', 'nutrition_density_score']].describe())"
      ],
      "metadata": {
        "id": "-AW1ZRBraBJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of the dataset:\", df_engineered.shape)"
      ],
      "metadata": {
        "id": "kKTvO0b1WsSR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the descriptive statistics of df_food\n",
        "df_engineered.describe()"
      ],
      "metadata": {
        "id": "8ZcOVSMyLcLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understanding the data types in df_food\n",
        "df_engineered.dtypes"
      ],
      "metadata": {
        "id": "OTxnBTVyLetm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 2: Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "QMHlIgdDG_QZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 Nutritional Value analysis**\n",
        "\n",
        "Used SQL queries to analyze the distribution of nutritional values"
      ],
      "metadata": {
        "id": "lo44YPQjdT1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create temporary global variables for pandasql\n",
        "locals_dict = {'df_engineered': df_engineered}\n",
        "\n",
        "# Average nutritional values by category query\n",
        "query1 = \"\"\"\n",
        "SELECT\n",
        "    categories,\n",
        "    COUNT(*) as product_count,\n",
        "    ROUND(AVG(energy_100g), 2) as avg_energy,\n",
        "    ROUND(AVG(proteins_100g), 2) as avg_proteins,\n",
        "    ROUND(AVG(carbohydrates_100g), 2) as avg_carbs,\n",
        "    ROUND(AVG(fat_100g), 2) as avg_fat\n",
        "FROM df_engineered\n",
        "WHERE categories != ''\n",
        "GROUP BY categories\n",
        "HAVING product_count > 10\n",
        "ORDER BY product_count DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "# High protein foods query\n",
        "query2 = \"\"\"\n",
        "SELECT\n",
        "    product_name,\n",
        "    brands,\n",
        "    ROUND(proteins_100g, 2) as proteins_100g,\n",
        "    ROUND(energy_100g, 2) as energy_100g\n",
        "FROM df_engineered\n",
        "WHERE proteins_100g > 20\n",
        "    AND product_name != ''\n",
        "ORDER BY proteins_100g DESC\n",
        "LIMIT 10\n",
        "\"\"\"\n",
        "\n",
        "results = {}\n",
        "results['category_nutrition'] = sqldf(query1, locals_dict)\n",
        "results['high_protein'] = sqldf(query2, locals_dict)"
      ],
      "metadata": {
        "id": "WtSI9PvAI-03"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Display results\n",
        "print(\"\\nTop Categories by Product Count and Average Nutrition:\")\n",
        "print(\"-\" * 50)\n",
        "display(results['category_nutrition'])\n",
        "\n",
        "print(\"\\nTop High-Protein Foods:\")\n",
        "print(\"-\" * 50)\n",
        "display(results['high_protein'])"
      ],
      "metadata": {
        "id": "K2f3HJNFBKJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results['category_nutrition']"
      ],
      "metadata": {
        "id": "7gEzdaVyYbtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Nutritional Balance Analysis\n"
      ],
      "metadata": {
        "id": "sA1Ik1QYdPWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balance = df_engineered.groupby('categories').agg({\n",
        "        'proteins_100g': ['mean', 'std'],\n",
        "        'carbohydrates_100g': ['mean', 'std'],\n",
        "        'fat_100g': ['mean', 'std']\n",
        "    }).round(2)\n",
        "\n",
        "print(\"\\nTop 10 Categories by Nutritional Balance:\")\n",
        "display(balance.head(10))"
      ],
      "metadata": {
        "id": "lR7UwDOsJRhK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Nutrition Density Score Statistics"
      ],
      "metadata": {
        "id": "IFzAzJhlc-zU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nNutrition Density Score Statistics:\")\n",
        "display(df_engineered['nutrition_density_score'].describe())"
      ],
      "metadata": {
        "id": "3eH-2ys_b6PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Show top 10 most nutrient-dense foods"
      ],
      "metadata": {
        "id": "4k1WFpHBdIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTop 10 Most Nutrient-Dense Foods:\")\n",
        "top_foods = df_engineered.nlargest(10, 'nutrition_density_score')[\n",
        "    ['product_name', 'nutrition_density_score', 'nutrition_density_category']]\n",
        "display(top_foods)"
      ],
      "metadata": {
        "id": "I3VXvHKVdIou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.2 Plots**\n",
        "\n",
        "####1. Distribution of Nutrition Density Scores"
      ],
      "metadata": {
        "id": "mhMOEIhQbtZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "fig = px.histogram(df_engineered, x='nutrition_density_score', nbins=50,\n",
        "                   title='Distribution of Nutrition Density Scores',\n",
        "                   range_x=[-3000, 3000],\n",
        "                   log_y=True,  # Log scale for the y-axis\n",
        "                   color_discrete_sequence=['orange'])\n",
        "\n",
        "\n",
        "fig.update_traces(marker_line_color='black',\n",
        "                  marker_line_width=1.5)\n",
        "\n",
        "fig.update_layout(yaxis_title='Log of Count')\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "pLUMcb2r7G4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.express as px\n",
        "\n",
        "\n",
        "category_counts = df_engineered['nutrition_density_category'].value_counts().reset_index()\n",
        "category_counts.columns = ['Category', 'Count']\n",
        "\n",
        "fig = px.bar(category_counts, x='Category', y='Count',\n",
        "             title='Distribution of Nutrition Categories',\n",
        "             labels={'Count': 'Number of Products'},\n",
        "             color_discrete_sequence=['orange'])\n",
        "\n",
        "\n",
        "fig.update_traces(text=category_counts['Count'], textposition='outside')\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "iByBw88N7Zz0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####2. Distribution of Nutrition Categories"
      ],
      "metadata": {
        "id": "gxjRCPb2b5M0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####3. Plot nutrition distribution for top categories"
      ],
      "metadata": {
        "id": "-XtZ1w10bHAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = results['category_nutrition'].sort_values(by='avg_energy', ascending=False)\n",
        "\n",
        "fig = px.bar(data, x='categories', y='avg_energy',\n",
        "             title='Average Energy Content by Category',\n",
        "             labels={'avg_energy': 'Energy (per 100g)', 'categories': 'Category'},\n",
        "             color='categories',\n",
        "             color_discrete_sequence=px.colors.qualitative.Plotly,\n",
        "             height=1000)\n",
        "\n",
        "\n",
        "fig.update_traces(textposition='outside')\n",
        "fig.for_each_trace(lambda t: t.update(text=t.y))\n",
        "\n",
        "\n",
        "fig.update_layout(xaxis_tickangle=-45)\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "lCmcdXDq9prv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####4. Plot distributions of main nutrients\n"
      ],
      "metadata": {
        "id": "dYhUC3v8bdFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "# List of nutrients\n",
        "nutrients = ['energy_100g', 'proteins_100g', 'carbohydrates_100g', 'fat_100g']\n",
        "\n",
        "\n",
        "fig = make_subplots(rows=2, cols=2, subplot_titles=[f'Distribution of {nutrient}' for nutrient in nutrients])\n",
        "\n",
        "\n",
        "positions = [(i, j) for i in range(1, 3) for j in range(1, 3)]\n",
        "\n",
        "\n",
        "for nutrient, pos in zip(nutrients, positions):\n",
        "    trace = go.Histogram(\n",
        "        x=df_engineered[nutrient],\n",
        "        nbinsx=50,\n",
        "        marker=dict(\n",
        "            line=dict(color='black', width=1.5)\n",
        "        )\n",
        "    )  # Histogram for each nutrient\n",
        "    fig.add_trace(trace, row=pos[0], col=pos[1])\n",
        "\n",
        "\n",
        "fig.update_layout(\n",
        "    height=1000,\n",
        "    width=1600,\n",
        "    title_text=\"Nutrient Distributions in Food Products\",\n",
        "    showlegend=False\n",
        ")\n",
        "\n",
        "\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "ScYYjXlaABvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####5. Correlation Matrix of Nutritional Values"
      ],
      "metadata": {
        "id": "WcRV0-EibUgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nutrition_cols = ['energy_100g', 'proteins_100g', 'carbohydrates_100g',\n",
        "                  'fat_100g', 'fiber_100g', 'salt_100g']\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(df_engineered[nutrition_cols].corr(),\n",
        "            annot=True,\n",
        "            cmap='RdBu',\n",
        "            center=0)\n",
        "plt.title('Correlation between Nutritional Values')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5BRNwwitXBpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_engineered.to_csv('processed_food_data.csv', index=False)\n",
        "\n",
        "print(\"\\nProcessing complete! Dataset is ready for modeling.\")"
      ],
      "metadata": {
        "id": "CqvssO6KPrOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 3: Modeling: Logistic Regression"
      ],
      "metadata": {
        "id": "EQ6Xg8i3aJWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.1 Define Features and Target**\n",
        "Prepare the dataset for modeling by selecting features and defining the target variable.\n",
        "\n",
        "Features: Nutritional attributes (e.g., energy_100g, proteins_100g)\n",
        "\n",
        "Target: nutrition_density_category -  \"Poor,\" \"Fair,\" \"Good,\" or \"Excellent.\"\n",
        "\n",
        "Fill missing values in features with the median and in the target with the most common category."
      ],
      "metadata": {
        "id": "SkF5OjXKXyam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Lib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "dwpeSo5fYQjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Features and Target\n",
        "selected_columns = [\n",
        "    'energy_100g', 'proteins_100g', 'carbohydrates_100g',\n",
        "    'fat_100g', 'fiber_100g', 'salt_100g', 'nutrition_density_score'\n",
        "]\n",
        "features = df_engineered[selected_columns]\n",
        "target = df_engineered['nutrition_density_category']\n",
        "\n",
        "# Fill missing values\n",
        "\n",
        "features = features.fillna(features.median())\n",
        "target = target.fillna(target.mode()[0])\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "## QA Check nan values\n",
        "print(\"Number of NaN values in X_train:\")\n",
        "print(X_train.isna().sum())\n",
        "\n",
        "print(\"Number of Inf values in X_train:\")\n",
        "print(np.isinf(X_train).sum())\n",
        "\n",
        "# Replace inf and -inf in the 'nutrition_density_score'\n",
        "X_train['nutrition_density_score'] = X_train['nutrition_density_score'].replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "# Fill NaN  with the column median\n",
        "X_train['nutrition_density_score'] = X_train['nutrition_density_score'].fillna(X_train['nutrition_density_score'].median())\n",
        "\n",
        "# Repeat  X_test\n",
        "X_test['nutrition_density_score'] = X_test['nutrition_density_score'].replace([np.inf, -np.inf], np.nan)\n",
        "X_test['nutrition_density_score'] = X_test['nutrition_density_score'].fillna(X_test['nutrition_density_score'].median())"
      ],
      "metadata": {
        "id": "aLeIblNhAdrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize data"
      ],
      "metadata": {
        "id": "Jjb_YtdiB9mP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "spNUBSAFB52g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.2 Baseline Model - Logistic Regression**\n",
        "Establish a baseline model\n",
        "\n",
        "Predict\n",
        "\n",
        "Evaluate result"
      ],
      "metadata": {
        "id": "LePwMxlkBD3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Model - Logistic Regression\n",
        "print(\"\\n--- Logistic Regression ---\")\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predictions\n",
        "y_pred_log = log_reg.predict(X_test)\n",
        "\n",
        "# Evaluate result\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred_log))\n",
        "\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_log)\n",
        "print(f\"Baseline Model Accuracy: {baseline_accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "wpE6Q5hkBFKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.3 Validate the Classification Model**\n",
        "\n",
        "\n",
        "Perform cross-validation to confirm the model generalizes well across different splits of the data.\n",
        "\n",
        "Use confusion matrices for cross-validation folds."
      ],
      "metadata": {
        "id": "JJqd5XGlC91d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA and prep data"
      ],
      "metadata": {
        "id": "BYBKVmyTEIqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "###QA##\n",
        "\n",
        "# Inspect features for invalid values\n",
        "print(\"Number of NaN values in features:\")\n",
        "print(features.isna().sum())\n",
        "\n",
        "print(\"Number of Inf values in features:\")\n",
        "print(np.isinf(features).sum())\n",
        "\n",
        "# Replace inf and NaN\n",
        "features = features.replace([np.inf, -np.inf], np.nan)\n",
        "features = features.fillna(features.median())\n",
        "\n",
        "# Clip extreme values\n",
        "features = features.clip(lower=features.quantile(0.01), upper=features.quantile(0.99), axis=1)\n",
        "\n",
        "\n",
        "## Scale the features\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)"
      ],
      "metadata": {
        "id": "rC5DV5OBDOW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3.4 Perform cross-validation**\n",
        "\n",
        "Fit the Logistic Regression model on:\n",
        "\n",
        "\n",
        "*   Maximum iterations (max_iter) set to 200.\n",
        "\n",
        "*   Random seed set to 42.\n",
        "\n",
        "\n",
        "\n",
        "Perform 5-fold cross-validation using the cross_val_score function with accuracy as the scoring metric.\n",
        "\n",
        "Store the cross-validation accuracy scores in log_reg_cv_scores.\n",
        "\n",
        "Calculate the mean accuracy and store it in log_reg_mean_acc."
      ],
      "metadata": {
        "id": "mcJvdaX8EB84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Perform cross-validation ##\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "log_reg = LogisticRegression(max_iter=200, random_state=42)\n",
        "log_reg_cv_scores = cross_val_score(log_reg, features_scaled, target, cv=5, scoring='accuracy')\n",
        "\n",
        "print(\"\\nLogistic Regression Cross Validation Accuracy   Scores:\")\n",
        "print(log_reg_cv_scores)\n",
        "print(f\"Mean Accuracy: {log_reg_cv_scores.mean():.2f}\")"
      ],
      "metadata": {
        "id": "lT78UDk-Dxw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 4: Modeling: Random Forest"
      ],
      "metadata": {
        "id": "2gRT1WQlFKCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.1 Train and Evaluate Random Forest Classifier**\n",
        "Fit a Random Forest classifier on X_train and y_train using the following hyperparameters:\n",
        "\n",
        "\n",
        "\n",
        "*   class_weight set to \"balanced\".\n",
        "*   n_estimators (number of trees) set to 120.\n",
        "*   max_depth set to 30.\n",
        "*   Random seed set to 42.\n",
        "\n",
        "\n",
        "\n",
        "Calculate the accuracy of the model on the test set using the score method and store it in rf_acc.\n",
        "\n",
        "Compute confusion matrix for  predictions and save it as rf_confusion."
      ],
      "metadata": {
        "id": "hiMfgNi-GAnX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Fit Random Forest\n",
        "rf_model = RandomForestClassifier(\n",
        "    class_weight='balanced', n_estimators=120, max_depth=30, random_state=42\n",
        ")\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate accuracy\n",
        "rf_acc = rf_model.score(X_test, y_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "rf_confusion = confusion_matrix(y_test, rf_model.predict(X_test))\n",
        "\n",
        "print(f\"Random Forest   Test Accuracy : {rf_acc:.2f}\")\n",
        "print(\"Random Forest  Confusion Matrix  :\")\n",
        "print(rf_confusion)"
      ],
      "metadata": {
        "id": "LgZH66FXGy1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class_labels = rf_model.classes_  # Get class labels\n",
        "\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(rf_confusion, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=class_labels, yticklabels=class_labels)\n",
        "\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jTqjHonzBgFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.2 Plot Feature Importances**\n",
        "\n",
        "Understand the key drivers behind the nutrition_density_category predictions made by the Random Forest model.\n",
        "\n",
        "Use feature importance to visualize the most important features.\n",
        "\n"
      ],
      "metadata": {
        "id": "kUm7quw_IahI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Extract feature names from the DataFrame\n",
        "feature_names = features.columns\n",
        "\n",
        "# Extracting feature importances from the RF model\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame with the features and their importances\n",
        "features_df = pd.DataFrame({\n",
        "    'Feature': feature_names,\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "features_df = features_df.sort_values(by='Importance', ascending=True)\n",
        "\n",
        "# Barchart for Importances\n",
        "fig = px.bar(features_df, x='Importance', y='Feature', orientation='h',\n",
        "             title='Feature Importances - Random Forest',\n",
        "             labels={'Importance': 'Importance Score', 'Feature': 'Feature'},\n",
        "             color='Importance',  # Color the bars by importance\n",
        "             color_continuous_scale=px.colors.sequential.Viridis)\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Importance Score',\n",
        "    yaxis_title='Feature',\n",
        "    coloraxis_showscale=True  # Show the color scale\n",
        ")\n",
        "\n",
        "# Show the plot\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "Lstr3SB-4Mcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Insights from Chart:** Based on our the feature importances calculated, nutrition_density_score is by far the strongest feature to determine whether a food is health or not, followed by salt per 100g and calories by 100g."
      ],
      "metadata": {
        "id": "AIbmUQpq9tRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3 Insights from Random Forest Model**\n",
        "The RandomForest model's feature importance analysis revealed critical insights into the factors that most significantly influence the nutritional quality of food products. The analysis focused on two primary features: nutrition_density_score and salt_100g, which are instrumental in determining the overall nutritional categorization of food products.\n",
        "\n",
        "## 1. Nutrition Density Score (Importance: 0.599683)\n",
        "\n",
        "### Explanation:\n",
        "The nutrition_density_score serves as a comprehensive metric that integrates essential nutrients such as proteins and fiber with limiting factors such as salt. This integration makes it a robust indicator of overall nutritional value.\n",
        "### Implications:\n",
        "Given its comprehensive nature, the nutrition_density_score emerges as the predominant predictor in our model. It directly correlates with the categorization into nutritional quality bands, effectively distinguishing between higher and lower nutritional values. This feature's dominance underscores the importance of balanced nutrition in the evaluation of food quality.\n",
        "\n",
        "## 2. Salt Content (Importance: 0.171232)\n",
        "\n",
        "### Explanation:\n",
        "Salt content, measured as salt_100g, plays a critical role in nutritional assessments due to its impact on health. High salt levels are known to detract from nutritional value, significantly affecting health ratings.\n",
        "### Implications:\n",
        "The substantial influence of salt content on the nutrition_density_score confirms it as a key predictor for identifying products likely categorized as Fair or Poor in nutritional quality. This finding aligns with current health guidelines which advocate for lower sodium intake to prevent various health issues."
      ],
      "metadata": {
        "id": "R-ObN3RULNro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 5: Applying the Feed Forward Neural Network"
      ],
      "metadata": {
        "id": "BUjAtYhrceNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "dPfmjKnWcdi6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "FJ6v7oBGgGhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Fit label encoder on training labels and transform\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "\n",
        "# Convert integer labels to one-hot encoded vectors\n",
        "y_train_onehot = to_categorical(y_train_encoded)\n",
        "y_test_onehot = to_categorical(y_test_encoded)"
      ],
      "metadata": {
        "id": "8l-qXl5_gaHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer and first hidden layer\n",
        "model.add(Dense(64, activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "model.add(Dense(32, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "9nftxE6QgcVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_onehot,\n",
        "    epochs=20,\n",
        "    batch_size=128,\n",
        "    validation_data=(X_test, y_test_onehot)\n",
        ")"
      ],
      "metadata": {
        "id": "x1Gq-r7rgwQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train')\n",
        "plt.plot(history.history['val_accuracy'], label='Test')\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "# Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train')\n",
        "plt.plot(history.history['val_loss'], label='Test')\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pSXsjADQg5Vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the Model\n",
        "loss, accuracy = model.evaluate(X_test, y_test_onehot, verbose=0)\n",
        "print(f\"Test Loss: {loss:.4f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "k4cau2Axg81_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict class probabilities\n",
        "y_pred_prob = model.predict(X_test)\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred_classes = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Decode class labels back to original categories\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred_classes)"
      ],
      "metadata": {
        "id": "I2JGB0Bdhwz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# True labels\n",
        "y_true = y_test\n",
        "\n",
        "# Predicted labels\n",
        "y_pred = y_pred_labels\n",
        "\n",
        "# Classification report\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print('Confusion Matrix')\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "9XXqfcO7h5Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 6: K-Means Clustering\n",
        "\n",
        "## Objective:\n",
        "Our next step is to segment food products into distinct groups based on their nutritional profiles using K-Means clustering, informed by the most significant features identified through RandomForest analysis.\n",
        "\n",
        "## Methodology:\n",
        "\n",
        "**Feature Selection:** Utilize RandomForest to determine the key nutritional attributes that significantly impact food quality.\n",
        "Clustering Execution: Implement K-Means clustering using these selected features to categorize food products into meaningful clusters.\n",
        "\n",
        "**Rationale:**\n",
        "This approach ensures that our clustering is focused on the most impactful nutritional factors, providing clear, actionable insights into different food categories. This targeted analysis helps in identifying nutritional patterns and supports informed decision-making in food product development and marketing strategies.\n",
        "\n",
        "**Implications:**\n",
        "Employing K-Means with features identified by RandomForest allows for precise segmentation of the food market, facilitating enhanced product positioning and health-focused consumer outreach."
      ],
      "metadata": {
        "id": "B7bpdu2fOO9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.1 Select Features**\n",
        "\n",
        "Based on the feature importance from Random Forest model, we will include the following features:\n",
        "\n",
        "\n",
        "\n",
        "*   nutrition_density_score\n",
        "*   salt_100g\n",
        "*   energy_100g\n",
        "*   List item\n",
        "* proteins_100g\n",
        "* fiber_100g\n",
        "* carbohydrates_100g\n",
        "* fat_100g\n"
      ],
      "metadata": {
        "id": "x2kTn08GOim7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Select features based on Random Forest importance\n",
        "selected_features = ['nutrition_density_score', 'salt_100g', 'energy_100g',\n",
        "                     'proteins_100g', 'fiber_100g', 'carbohydrates_100g', 'fat_100g']\n",
        "\n",
        "# Extract  features\n",
        "features_for_clustering = df_engineered[selected_features]"
      ],
      "metadata": {
        "id": "oaA8lGerLxtv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "QA & clean data (fill Nan)"
      ],
      "metadata": {
        "id": "1rsUVs78Aiej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###QA###\n",
        "# Check for Inf or NaN values in features\n",
        "print(\"Number of NaN values in features:\")\n",
        "print(features_for_clustering.isna().sum())\n",
        "\n",
        "print(\"\\nNumber of Inf values in features:\")\n",
        "print(np.isinf(features_for_clustering).sum())\n",
        "\n",
        "# Create a cleaned version of the Df\n",
        "## avoid warning\n",
        "features_for_clustering_cleaned = features_for_clustering.copy()\n",
        "\n",
        "# Replace Inf and -Inf with NaN\n",
        "features_for_clustering_cleaned.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Replace NaN values with the median of each column\n",
        "features_for_clustering_cleaned.fillna(features_for_clustering_cleaned.median(), inplace=True)\n",
        "\n",
        "# Validate the cleaned Df\n",
        "print(\"Remaining NaN values:\", features_for_clustering_cleaned.isna().sum())\n",
        "print(\"Remaining Inf values:\", np.isinf(features_for_clustering_cleaned).sum())"
      ],
      "metadata": {
        "id": "_nEqoj9yPSZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scale features"
      ],
      "metadata": {
        "id": "iy994LEkAZwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features_for_clustering_cleaned)"
      ],
      "metadata": {
        "id": "R6HN9VBHAV60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.2 Determine Optimal Number of Clusters (Elbow Method)**"
      ],
      "metadata": {
        "id": "NMF0TL11QDmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine optimal k using Elbow Method\n",
        "inertia = []\n",
        "k_values = range(1, 11)\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(features_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "# Plot the Elbow Curve -- to find the optimal number of clusters\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, inertia, marker='o')\n",
        "plt.title('Elbow Method for Optimal k')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Inertia')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V-EM8IEhQEIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After k=4, the rate of decrease becomes more gradual, which means diminishing returns in clustering improvement.\n",
        "\n",
        "Optimal - > K = 4"
      ],
      "metadata": {
        "id": "4UL_A7P8Qbf-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **6.3 Run K-Means Clustering with k=4:**\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ],
      "metadata": {
        "id": "OO9rz-10Qwye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fit K-Means with k=4\n",
        "optimal_k = 4\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "clusters = kmeans.fit_predict(features_scaled)\n",
        "\n",
        "#   Add cluster labels to the original DataFrame\n",
        "df_engineered['Cluster'] = clusters\n",
        "\n",
        "# Analyze Cluster Centers\n",
        "cluster_centers = pd.DataFrame(\n",
        "    scaler.inverse_transform(kmeans.cluster_centers_),\n",
        "    columns=selected_features\n",
        ")\n",
        "print(\"Cluster Centers:\")\n",
        "print(cluster_centers)"
      ],
      "metadata": {
        "id": "i0Wlg4b2Qvj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 7: Prepare Pairwise Cluster using Pandasql\n",
        "\n",
        "1. Use pandasql to boost efficency for preparing pairwise cluster visual\n",
        "\n",
        "2. Prep data and fix the inf and NaN issue before querying"
      ],
      "metadata": {
        "id": "jc5VJnvx944n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the global variable for pandasql\n",
        "locals_dict = {'df_engineered': df_engineered}\n",
        "\n",
        "## fix the  inf issue before processing\n",
        "# fix the NaN values before processing\n",
        "\n",
        "\n",
        "# Replace 'inf' and '-inf' with NaN in the Df\n",
        "df_engineered['nutrition_density_score'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Fill NaN values in 'nutrition_density_score' with the median\n",
        "median_nutrition_score = df_engineered['nutrition_density_score'].median()\n",
        "df_engineered['nutrition_density_score'].fillna(median_nutrition_score, inplace=True)\n",
        "\n",
        "# Verify the issue is resolved\n",
        "print(\"Number of 'inf' or 'NaN' values in 'nutrition_density_score':\")\n",
        "print(df_engineered['nutrition_density_score'].isnull().sum())\n"
      ],
      "metadata": {
        "id": "DhotDcKGgfed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check Cluster represntation counts and decide # of limit row to balance"
      ],
      "metadata": {
        "id": "hDJQYC3weg6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# SQL2: Select representative products for each cluster\n",
        "query_representative_points_test = \"\"\"\n",
        "      SELECT\n",
        "        Cluster,\n",
        "        nutrition_density_score,\n",
        "        salt_100g,\n",
        "        energy_100g,\n",
        "        proteins_100g,\n",
        "        fiber_100g,\n",
        "        carbohydrates_100g,\n",
        "        fat_100g,\n",
        "        ROW_NUMBER() OVER (PARTITION BY Cluster ORDER BY nutrition_density_score DESC) as row_num\n",
        "    FROM df_engineered\n",
        "    WHERE\n",
        "        Cluster IS NOT NULL\n",
        "        AND nutrition_density_score IS NOT NULL\n",
        "        AND nutrition_density_score NOT IN ('inf', '-inf')\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "representative_points_test = sqldf(query_representative_points_test, locals_dict)\n",
        "\n",
        "\n",
        "# Check cluster representation counts\n",
        "print(\"Cluster Representation :\")\n",
        "print(representative_points_test['Cluster'].value_counts())\n",
        "print(representative_points_test)\n"
      ],
      "metadata": {
        "id": "Sa3tdAsUeJIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the global variable for pandasql\n",
        "locals_dict = {'df_engineered': df_engineered}\n",
        "\n",
        "##not using##\n",
        "'''\n",
        "#SQL 1: Compute average nutritional values by cluster\n",
        "\n",
        "query_clusters = \"\"\"\n",
        "SELECT\n",
        "    Cluster,\n",
        "    ROUND(AVG(nutrition_density_score), 2) as avg_nutrition_density,\n",
        "    ROUND(AVG(salt_100g), 2) as avg_salt,\n",
        "    ROUND(AVG(energy_100g), 2) as avg_energy,\n",
        "    ROUND(AVG(proteins_100g), 2) as avg_proteins,\n",
        "    ROUND(AVG(fiber_100g), 2) as avg_fiber,\n",
        "    ROUND(AVG(carbohydrates_100g), 2) as avg_carbs,\n",
        "    ROUND(AVG(fat_100g), 2) as avg_fat\n",
        "FROM df_engineered\n",
        "GROUP BY Cluster\n",
        "ORDER BY Cluster\n",
        "\"\"\"\n",
        "\n",
        "cluster_averages = sqldf(query_clusters, locals_dict)\n",
        "\n",
        "print(\"Cluster Averages:\")\n",
        "print(cluster_averages)\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# SQL2: Select representative products for each cluster\n",
        "query_representative_points_filtered = \"\"\"\n",
        "WITH ranked_points AS (\n",
        "       SELECT\n",
        "        Cluster,\n",
        "        nutrition_density_score,\n",
        "        salt_100g,\n",
        "        energy_100g,\n",
        "        proteins_100g,\n",
        "        fiber_100g,\n",
        "        carbohydrates_100g,\n",
        "        fat_100g,\n",
        "        ROW_NUMBER() OVER (PARTITION BY Cluster ORDER BY nutrition_density_score DESC) as row_num\n",
        "    FROM df_engineered\n",
        "    WHERE\n",
        "        Cluster IS NOT NULL\n",
        "        AND nutrition_density_score IS NOT NULL\n",
        "        AND nutrition_density_score NOT IN ('inf', '-inf')\n",
        ")\n",
        "SELECT *\n",
        "FROM ranked_points\n",
        "WHERE row_num <= 4000\n",
        "ORDER BY Cluster, row_num\n",
        "\"\"\"\n",
        " ## limit row to balance based on finding in cluster rep counts. cluster 1 has smallest 4000.\n",
        "\n",
        "representative_points = sqldf(query_representative_points_filtered, locals_dict)\n",
        "\n",
        "\n",
        "# Check cluster representation counts\n",
        "print(\"Cluster Representation :\")\n",
        "print(representative_points['Cluster'].value_counts())\n",
        "\n",
        "\"\"\"\n",
        "Cluster Representation :\n",
        "Cluster\n",
        "3    209202\n",
        "2     99561\n",
        "0     42221\n",
        "1      4055\n",
        "Name: count, dtype: int64\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "d7qH4Ro1-Hv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization for Pairwise Clusters"
      ],
      "metadata": {
        "id": "T7cihM9-Xxpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize\n",
        "\n",
        "\n",
        "# Ensure 'Cluster' column is treated as string\n",
        "representative_points['Cluster'] = representative_points['Cluster'].astype(str)\n",
        "\n",
        "# Visualization: Pairplot of representative points\n",
        "selected_features = [\n",
        "    'nutrition_density_score',\n",
        "    'salt_100g',\n",
        "    'energy_100g',\n",
        "    'proteins_100g',\n",
        "    'fiber_100g',\n",
        "    'carbohydrates_100g',\n",
        "    'fat_100g'\n",
        "]\n",
        "\n",
        "sns.pairplot(\n",
        "    representative_points,\n",
        "    vars=selected_features,\n",
        "    hue='Cluster',\n",
        "    palette='viridis',\n",
        "    diag_kind='kde',\n",
        "    markers=[\"o\", \"s\", \"D\", \"P\"]\n",
        ")\n",
        "plt.suptitle('Pairplot of Representative Points by Cluster', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#QA\n",
        "# Display a summary of representative points\n",
        "print(\"\\nRepresentative Points :\")\n",
        "print(representative_points)"
      ],
      "metadata": {
        "id": "tn9USk2LXu8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Part 8: Analysis of Clusters:\n",
        "\n",
        "## Cluster Profiles:\n",
        "\n",
        "* Cluster 0: High-protein, high-fat foods (e.g., peanuts or protein bars).\n",
        "* Cluster 1: High-salt, mid-carb foods (e.g., SPAM or Sausage).\n",
        "* Cluster 2: High-carb, high-fiber foods (e.g., Oats or black bread).\n",
        "* Cluster 3: Low-calorie, low-fat foods (e.g., apple, tomato, or vegetables).\n",
        "\n",
        "## Insights:\n",
        "* Cluster 0 (High-protein, high-fat, moderate energy) Market as high-energy snacks; consider low-fat versions for calorie-conscious consumers. EG. hiker ?\n",
        "* Cluster 1 (high-salt foods) may need reformulation to reduce salt for health-conscious consumers.\n",
        "* Cluster 2 (high-carb, high-fiber foods) could be marketed as energy-dense and fiber-rich products for athletes.\n",
        "* Cluster 3 (low-calorie foods) can be targeted to consumers having diet."
      ],
      "metadata": {
        "id": "TTVQjzpuRkqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis of Pairwise Trends and Cluster Interpretations\n",
        "\n",
        "**Overview of Key Trends:**  \n",
        "A notable positive correlation exists between the energy content (`energy_100g`) and fat content (`fat_100g`) across our food product dataset. This correlation underscores a fundamental nutritional principle: fat is more energy-dense than proteins or carbohydrates. Consequently, food products with higher fat content tend to have higher caloric values.\n",
        "\n",
        "**Cluster-Specific Analysis:**\n",
        "\n",
        "1. **Cluster 0 (High-Protein, High-Fat Foods):**\n",
        "   - **Examples:** Peanuts, Protein Bars\n",
        "   - **Interpretation:** Foods in this cluster are characterized by their high energy density, primarily driven by their significant fat content. This aligns perfectly with the observed positive correlation, as these foods utilize fat as a primary source of calories, supporting their use in energy-demanding contexts.\n",
        "\n",
        "2. **Cluster 1 (High-Salt, Mid-Carb Foods):**\n",
        "   - **Examples:** SPAM, Sausage\n",
        "   - **Interpretation:** While also following the upward trend between fat and energy, this cluster exhibits a less pronounced slope. This variation suggests that, besides fat, other macronutrients like carbohydrates and proteins also contribute to the energy content, albeit to a lesser extent. The presence of moderate carbohydrates moderates the direct impact of fat on energy levels.\n",
        "\n",
        "3. **Cluster 2 (High-Carb, High-Fiber Foods):**\n",
        "   - **Examples:** Oats, Black Bread\n",
        "   - **Interpretation:** This cluster displays a milder trend between fat and energy, indicating that carbohydrates play a significant role in energy provision. The high fiber content also suggests health benefits beyond energy provision, aligning these products with dietary recommendations for fiber intake.\n",
        "\n",
        "4. **Cluster 3 (Low-Calorie, Low-Fat Foods):**\n",
        "   - **Examples:** Vegetables, Fruits\n",
        "   - **Interpretation:** Representing the low end of the trend, these products are both low in fat and low in energy. This cluster illustrates the minimal impact of fat on the energy content, which is consistent with their positioning as diet-friendly options that minimize calorie intake without sacrificing volume.\n",
        "\n",
        "**Detailed Inisghts and Potential Market Uses:**\n",
        "\n",
        "Fat content has a clear link to energy levels in various food groups, showing just how different nutrients affect the energy value of food.\n",
        "\n",
        "These insights are super helpful for food manufacturers and health experts as they develop or suggest products that meet specific dietary needs or health goals. Each food cluster provides specific chances for improving nutrition and marketing, ensuring that consumer needs are addressed accurately and with well-supported evidence.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WaVzvsKoNtYF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion and Recommendations\n",
        "\n",
        "### Tailoring Nutrition to Consumer Needs\n",
        "\n",
        "Our analysis effectively segments food products into clusters with distinct nutritional characteristics. This refined understanding allows stakeholders to cater their products more precisely to the dietary preferences and health needs of diverse groups.\n",
        "\n",
        "#### Cluster Benefits, Target Audiences, and Cautions\n",
        "\n",
        "- **Cluster 0: High-Protein, High-Fat Foods**\n",
        "  - **Target Audience:** Bodybuilders and Fitness Enthusiasts\n",
        "  - **Benefits:** Ideal for those requiring sustained energy and muscle repair, such as bodybuilders and fitness enthusiasts. Examples include nuts, seeds, and protein bars.\n",
        "  - **Cautions:** Individuals with cardiovascular concerns or those on a low-fat diet might want to limit intake from this cluster due to the high fat content.\n",
        "\n",
        "- **Cluster 1: High-Salt, Mid-Carb Foods**\n",
        "  - **Target Audience:** Endurance Athletes\n",
        "  - **Benefits:** Useful for endurance athletes who lose significant salt through sweating and need quick energy from carbohydrates.\n",
        "  - **Cautions:** Individuals with hypertension or heart disease should avoid high-salt foods to manage blood pressure and heart health effectively.\n",
        "\n",
        "- **Cluster 2: High-Carb, High-Fiber Foods**\n",
        "  - **Target Audience:** Students, Office Workers, and Diabetics\n",
        "  - **Benefits:** Provides slow-releasing energy ideal for long periods of mental exertion faced by students and office workers; high fiber content is also beneficial for diabetics managing blood sugar levels.\n",
        "  - **Cautions:** Those on ketogenic or low-carb diets should avoid this cluster due to its high carbohydrate content.\n",
        "\n",
        "- **Cluster 3: Low-Calorie, Low-Fat Foods**\n",
        "  - **Target Audience:** Weight Loss Participants, Health-Conscious Consumers, and the Elderly\n",
        "  - **Benefits:** Supports weight management with low-calorie content and is suitable for the elderly seeking nutrient-dense, easy-to-digest foods. Examples include leafy greens, fresh fruits, and vegetables.\n",
        "  - **Cautions:** Athletes or individuals with high-caloric needs might find these foods insufficient for their energy requirements.\n",
        "\n",
        "### Implementing Insights for Market Impact\n",
        "\n",
        "Understanding these clusters helps manufacturers and health professionals tailor products precisely to meet the nutritional preferences and requirements of different consumer segments. This targeted approach not only enhances consumer satisfaction but also promotes healthier dietary choices, contributing to a better overall food environment.\n",
        "\n",
        "We recommend stakeholders utilize these insights to develop specialized product lines catering to the nuanced demands of these diverse consumer segments, thereby enhancing both market presence and consumer health outcomes.\n",
        "\n"
      ],
      "metadata": {
        "id": "OBA50MxoE9nI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j_MBl3i_E-Fx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}